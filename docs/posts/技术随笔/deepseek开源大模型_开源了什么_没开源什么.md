## 开篇

DeepSeek 开源大模型，它到底开源了什么？没开源什么？

DeepSeek 的爆火除了自身的技术创新和架构创新硬实力外，选择开源也是一个推动热度至关重要的一个决定。

首先，它开放了模型架构和参数，也就是说开发者可以直接使用这个高性能模型，而不需要从头开始训练。还有他的混合专家（MoE）架构这种创新型技术，提供了一个新的思路。每个人都可以去修改和商业使用。

其次，它还开源了技术报告和配套工具，这就相当于将“秘籍”给你，还告诉你怎么检验自己练没练成。


**那它没开源什么？**

1. 训练数据，做技术的都知道一个大模型的质量和训练数据息息相关，而且很多数据是有版权的，所以很少会有人将大量的数据进行开源。
2. 训练代码和推理代码，DeepSeek 通过报告披露了一些他们的训练方法，但是这部分闭源情况下，想复现模型还是比较困难的。



## 最后

总的来说，DeepSeek的开源在模型架构、参数和配套工具方面做得不错，但在训练数据和完整训练框架方面有所保留。

但是作为使用者，它无疑给我们带来了极大的便利，未来的 AI 可能会像水和电一样，接入我们生活的各个场景中。







# 参考文档

DeepSeek 开源大模型（如 DeepSeek-R1 或特定版本的开源模型）在开放与未开放内容方面，通常遵循业界开源大模型的常规实践。以下是典型的开放与未开放内容总结：

开放的部分

模型权重与架构

预训练/微调模型权重：开放完整模型参数（如参数规模为7B、13B等），用户可直接下载和使用。模型架构设计：公开模型的结构细节（如Transformer层数、注意力机制等），支持用户通过代码复现架构。
基础代码

推理代码：提供模型推理的示例代码（如Hugging Face格式的加载脚本、生成文本的Demo）。训练框架：公开核心训练框架（如基于PyTorch或JAX的实现），但可能不包括完整的分布式训练优化细节。
文档与教程

快速入门指南：提供模型下载、推理、微调的基础教程。技术报告：公开模型的训练目标、超参数选择、关键实验数据（如数据混合比例、训练硬件配置等）。
基础工具链

数据处理示例：可能开放部分数据清洗、预处理的代码（如分词器实现）。评估工具：提供基础性能评估脚本（如MMLU、C-Eval等基准测试的接口）。


未开放的部分

完整训练数据

原始数据集：通常不会开放具体的训练数据（因版权、隐私等问题），但可能提供数据来源的说明或数据配比（如“80%互联网文本、20%书籍”）。数据清洗细节：如去重、毒性过滤等具体规则可能不完全公开。
高级训练优化技术

分布式训练配置：大规模训练的分布式策略（如多卡并行、通信优化）可能以黑箱形式提供。超参数调优细节：部分敏感超参数（如学习率策略、正则化参数）可能未完全披露。
内部工具与基础设施

私有训练框架：深度优化的训练框架（如定制版的分布式训练库）可能未开源。模型压缩/加速工具：针对生产环境的优化技术（如量化、蒸馏工具链）可能保留。
商业应用授权

特定场景的商用许可：某些开源协议（如Apache 2.0、MIT）允许免费商用，但具体条款需仔细阅读协议说明。部分功能或版本可能需要单独授权。


需要注意的边界

开源协议（License）
核查模型遵循的协议（如MIT、Apache 2.0、CC-BY-NC），可能存在商用限制（如禁止闭源、非商业用途要求等）。
模型版本差异
DeepSeek可能分阶段开源不同规模的模型（如1B/7B开放，但更大的30B版本仅提供API访问）。
社区与支持
开源模型的支持可能依赖社区（如GitHub Issues），而非官方直接维护。


如果需要具体信息，建议直接查阅 DeepSeek官方GitHub仓库 和 技术文档，关注其开源协议（如LICENSE文件）和模型卡（Model Card）中的详细说明。
